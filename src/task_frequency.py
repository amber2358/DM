import pandas as pd
import ast
import os
import jieba


def load_data(style):
    data_dir =  f'./data/{style}'
    
    itemsets_path = os.path.join(data_dir, 'merged_frequent_itemsets.json')
    itemsets_df = pd.read_json(itemsets_path)

    if isinstance(itemsets_df.loc[0, 'itemsets'], str):
        itemsets_df["itemsets"] = itemsets_df["itemsets"].apply(ast.literal_eval)

    return itemsets_df


def recommend_keyword(keyword, itemsets_df, top_n=5):
    keyword = keyword.strip()
    if not keyword:
        return "è¯·è¾“å…¥å…³é”®è¯å“¦~"

    words = list(jieba.cut(keyword))
    # print(words)
    if not words:
        return "æ— æ³•è¯†åˆ«æœ‰æ•ˆè¯è¯­ã€‚"

    word_to_related = {}
    for w in words:
        related = set()
        for _, row in itemsets_df.iterrows():
            items = row["itemsets"]
            if any(w in item for item in items):
                for item in items:
                    if item != w:
                        related.add(item)
        if related:
            word_to_related[w] = related

    if not word_to_related:
        return "ğŸ˜¢ æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³è¯ï¼Œå¯èƒ½æ˜¯æ–°è¯æˆ–è¯ä¹‰ç½•è§ã€‚"

    sets = list(word_to_related.values())
    common_related = set.intersection(*sets) if len(sets) > 1 else sets[0]

    if not common_related:
        result = "âš ï¸ å„å…³é”®è¯æ— å…±åŒæ¨èï¼Œä»¥ä¸‹æ˜¯å•ç‹¬æ¨èï¼š\n\n"
    else:
        result = "æ¨èï¼š\n" + "ã€".join(sorted(list(common_related)[:top_n])) + "\n\n"
        result += "åˆ†è¯æ¨èå¦‚ä¸‹ï¼š\n"

    for word, related in word_to_related.items():
        if related:
            items = sorted(list(related))[:top_n]
            result += f"ã€Œ{word}ã€ï¼š{'ã€'.join(items)}\n"

    return result

if __name__ == "__main__":
    style = "shi"
    keyword = "æ˜¥é›¨å±±æ°´è¯"
    df = load_data(style)
    result = recommend_keyword(keyword, df)
    print(f"æ¨èè¯è¯­: {result}")